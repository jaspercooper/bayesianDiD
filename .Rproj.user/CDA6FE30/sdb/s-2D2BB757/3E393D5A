{
    "contents" : "---\ntitle: \"Difference-in-Difference Estimation\"\nauthor: \"Jasper Cooper\"\noutput: ioslides_presentation\n---\n```{r,echo=F,warning=F,message=F}\nset.seed(12345)\nlibrary(CausalImpact)\nlibrary(ggplot2)\nlibrary(knitr)\n```\n\n\\(\\require{color}\\)\n\n## Plan \n\n  1. What it is and why people use it\n  \n  2. Causal identification \n  \n  3. Frequentist Approaches to Estimation \n  \n  4. Sources of Bias and Over-Confidence \n  \n  5. Some best practices\n  \n  6. What would google do?\n    - Bayesian Structural Time-Series \n    - An invitation to collaborate\n\n\n# What it is and why people use it\n\n## What it is\n\n- A method for constructing counterfactuals\n\n```{r,echo=FALSE,cache=T,warning=F,message=F}\n\n\ndat <- data.frame(\n  post = rep(1:10,each = 2),\n  treatment = rep(c(0,1),10)\n)\n\ndat$Y1 <- NA\ndat$Y0 <- NA\ndat$Y0[dat$treatment == 0] <- 10:1 + runif(10)\ndat$Y0[dat$treatment == 1] <- dat$Y0[dat$treatment == 0]+5\n\ndat$Y1 <- dat$Y0 + 2\ndat$Y <- NA\ndat$Y[dat$treatment == 0] <- dat$Y0[dat$treatment == 0]\ndat$Y[dat$treatment == 1&dat$post<6] <- dat$Y0[dat$treatment == 1&dat$post<6]\ndat$Y[dat$treatment == 1&dat$post>5] <- dat$Y1[dat$treatment == 1&dat$post>5]\ndat$Y_pred <- NA\ndat$Y_pred[dat$treatment == 1&dat$post>5] <- dat$Y0[dat$treatment == 1&dat$post>5]\ndat$treatment <- as.factor(dat$treatment)\n```\n```{r,echo=FALSE,cache=T,warning=F,message=F,fig.height=3}\nplot_dat_1 <- subset(dat,treatment == 1)\nY_at_end <- with(plot_dat_1,Y[post==10])\nY_at_start <- with(plot_dat_1,Y[post==1])\nggplot(plot_dat_1) + geom_line(aes(x = post, y = Y,color = treatment)) +\n  # geom_point(aes(x = post, y = Y_pred)) +\n  theme_bw() +\n  scale_color_discrete(\"\",labels = c(\"Treated\")) +\n  scale_x_continuous(\"Time\",\n                     breaks = c(2.5,5.5,7.5), \n                     labels = c(\"Pre\",\"Intervention\",\"Post\")) +\n  geom_vline(xintercept = 5.5) +\n  geom_hline(aes(yintercept = c(Y[post==1],\n                            Y[post==10])),\n             linetype = 2,size = .5) +\n  scale_y_continuous(\"Y\",breaks = round(c(0,15,10,5,Y_at_end,Y_at_start\n                            ),1)) +\n#   geom_segment(aes(x = 8, y = Y_pred[post==8], \n#                    xend = 8, yend = Y[post==8]),\n#                linetype = 3) +\n  coord_cartesian(ylim = c(0,17))\n\n```\n\n- $\\tau = 2$\n- $\\hat{\\tau} = -7.1$\n\n## What it is\n\n- A method for constructing counterfactuals\n\n```{r,echo=FALSE,cache=T,warning=F,message=F,fig.height=3}\nplot_dat_2 <- dat\n# I did a weird thing here and inverted the treatment indicator to keep the \n# colors constant, sorry about that:\nplot_dat_2$treatment <- as.factor(2-as.numeric(plot_dat_2$treatment))\nY_prediction <- with(plot_dat_2,Y_pred[post==7&treatment == 0])\nY_observed <- with(plot_dat_2,Y[post==7&treatment == 0])\nggplot(plot_dat_2) + geom_line(aes(x = post, y = Y,color = treatment)) +\n  geom_point(aes(x = post, y = Y_pred)) +\n  theme_bw() +\n  scale_color_discrete(\"\",labels = c(\"Treated\",\"Untreated\")) +\n  scale_x_continuous(\"Time\",\n                     breaks = c(2.5,5.5,7.5), \n                     labels = c(\"Pre\",\"Intervention\",\"Post\")) +\n  geom_vline(xintercept = 5.5) +\n  geom_hline(yintercept = c(Y_observed,\n                            Y_prediction),\n             linetype = 2,size = .5) +\n  scale_y_continuous(\"Y\",breaks = c(0,15,10,5,round(Y_observed,1),\n                                       round(Y_prediction,1))) +\n  geom_segment(x = 7, y = Y_prediction, \n                   xend = 7, yend = Y_observed,\n               linetype = 3)+\n  coord_cartesian(ylim = c(0,17))\n```\n\n- $\\tau = 2$ \n- $\\hat{\\tau} = 2$\n\n## What it is\n\n- We estimate causal effects as the difference between what we observe and what we predict we would have observed in the absence of \"treatment\"\n\n- Does not require that expected unobserved heterogeneity in baseline is equal cross-sectionally\n\n- Requires that you have $N \\geq 2$ and $T \\geq 2$\n\n## Why people use it\n\n- Often things we can't randomize, or that have already happened in a non-random way\n\n- Often we think we can predict outcomes for units based on time-invariant relationships with other units \n\n- If we can construct a valid synthetic control, we can provide causal estimate of effect of a non-randomized intervention\n\n- Everything hinges on the validity of the counterfactual predictions\n\n## Main disadvantages\n\n- Easy to have over-confident estimates (serial correlation)\n\n- Easy to have biased estimates (violation of identification assumptions)\n\n- People pay insufficient attention to ID assumptions, despite testable implications\n\n# Identification assumptions\n\n## Traditional concerns still apply\n\n  - Exclusion restriction \n    - Can't be anything about being assigned to the treatment that affects outcomes except for the treatment\n  \n  - SUTVA\n    - includes both inter-temporal and cross-unit spillovers \n    - Damian Clarke (2015) has a paper on how to do DiD in presence of spillovers\n\n## Stability in pre- and post-treatment relationship\n\nKey stability assumption:\n\n  - **if untreated**, those who **received treatment** would have an outcome equivalent to their outcome in the last pre-treatment period, **plus whatever change we model as a function of the untreated group in the post-treatment period** \n\n## Stability in pre- and post-treatment relationship\n\n  - Ideal situation = pre-treatment trends common across treatment and control groups\n  - then we use \"parallel paths\" assumption\n  \n    - but DiD sometimes viable in presence of group-specific trends\n    - if true relationship between predictors and counterfactual remains stable (stationary) throughout pre- and post-treatment periods\n  \n\n## Stability in pre- and post-treatment relationship\n\nIn the simplest case of common trends and two time periods\n\n  - we don't assume $E[Y(0)|Z=1] = E[Y(0)|Z=0]$\n\nbut: \n  \n  - $E[Y(0,1) - Y(0,0)|Z=1] = E[Y(0,1) - Y(0,0)|Z=0]$\n  \nWhere $Y(z_i,t)$\n\n\n## Traditional Approaches to Estimation \n\nSimplest: \n\n  - $E[Y_t|Z] = \\gamma + \\gamma^Z Z + \\gamma^P Post_t +{\\color{blue}\\gamma^Z_P} Post_t \\times Z$\n    - assumes parallel paths, immediate and uniform treatment effects\n\n$\\gamma = E[Y_0|0]$ \n\n$\\gamma^Z = E[Y_1|0]-E[Y_0|0]$\n\n$\\gamma_P = E[Y_0|1]-E[Y_0|0]$\n\n${\\color{blue}\\gamma^Z_P} = \\{E[Y_1|1]-E[Y_1|0]\\}-\\{E[Y_0|1]-E[Y_0|0]\\}$  \n\n## Traditional Approaches to Estimation \n\nTime FE: \n\n  - $E[Y_t|Z] = \\delta + \\sum^T_{\\tau = t_2} \\delta_\\tau \\mathbf{I}_{\\tau,t} + \\gamma^Z Z +{\\color{blue}\\gamma^Z_P} Post_t \\times Z$\n    - same as above, FE for pre-treatment should be common across groups\n\n## Traditional Approaches to Estimation \n\nGroup-specific (polynomial) trends:\n\n  - $E[Y_t|Z] = \\delta + \\sum^T_{\\tau = t_2} \\delta_\\tau \\mathbf{I}_{\\tau,t} +$ $\\gamma^Z Z +{\\color{blue}\\gamma^Z_P} Post_t \\times Z + \\sum_{r=1}^R \\gamma_r^Z t^r \\times Z$\n    - identified only in very specific cases (see Mora & Reggio 2012) \n    - Note: we are conditioning estimation of treatment effect, ${\\color{blue}\\gamma^Z_P}$ on the post-treatment trend, $\\gamma_r^Z t^r$ (not good!)\n    - often serial correlation induced by $\\gamma_r^Z$\n\n## Sources of Bias and Over-Confidence\n\nViolation of parallel assumptions\n\n```{r,echo=FALSE,cache=T,warning=F,message=F}\n\n\ndat <- data.frame(\n  post = rep(1:10,each = 2),\n  treatment = rep(c(0,1),10)\n)\n\ndat$Y1 <- NA\ndat$Y0 <- NA\ndat$Y0[dat$treatment == 0] <- 10:1 + runif(10)\ndat$Y0[dat$treatment == 1] <- 11-dat$Y0[dat$treatment == 0]\n\ndat$Y1 <- dat$Y0\ndat$Y <- NA\ndat$Y[dat$treatment == 0] <- dat$Y0[dat$treatment == 0]\ndat$Y[dat$treatment == 1&dat$post<6] <- dat$Y0[dat$treatment == 1&dat$post<6]\ndat$Y[dat$treatment == 1&dat$post>5] <- dat$Y1[dat$treatment == 1&dat$post>5]\ndat$Y_pred <- NA\ndat$Y_pred[dat$treatment == 1&dat$post>5] <- dat$Y0[dat$treatment == 1&dat$post>5]\ndat$treatment <- as.factor(dat$treatment)\n```\n```{r,echo=FALSE,cache=T,warning=F,message=F,fig.height=3}\nplot_dat_3 <- dat\n# I did a weird thing here and inverted the treatment indicator to keep the \n# colors constant, sorry about that:\nplot_dat_3$treatment <- as.factor(2-as.numeric(plot_dat_3$treatment))\ndat$post_ <- (dat$post>5)*1\nDID_est <- coef(lm(Y ~ post_*treatment, dat))[\"post_:treatment1\"]\nggplot(plot_dat_3) + geom_line(aes(x = post, y = Y,color = treatment)) +\n  # geom_point(aes(x = post, y = Y_pred)) +\n  theme_bw() +\n  scale_color_discrete(\"\",labels = c(\"Treated\",\"Untreated\")) +\n  scale_x_continuous(\"Time\",\n                     breaks = c(2.5,5.5,7.5), \n                     labels = c(\"Pre\",\"Intervention\",\"Post\")) +\n  geom_vline(xintercept = 5.5) +\n  # geom_hline(yintercept = c(Y_observed,\n                            # Y_prediction),\n             # linetype = 2,size = .5) +\n  scale_y_continuous(\"Y\",breaks = c(0,15,10,5)) +\n#   geom_segment(x = 7, y = Y_prediction, \n#                    xend = 7, yend = Y_observed,\n#                linetype = 3)+\n  coord_cartesian(ylim = c(0,17))\n\n```\n\n- $\\tau = 0$\n- $\\hat{\\tau} = `r round(DID_est,1)`$\n\n## Sources of Bias and Over-Confidence\n\nSerial correlation \n\n- Using placebo law changes, Bertrand, Duflo Mullainthain (2004) find false of $\\approx .3$ even when accounting for AR(1) in covariance matrix (i.e. using $\\rho$)\n\n- Serial correlaiton induced by time-invariance of treatment variable \n\n- If many units in treatment and control (i.e. >50), can be corrected through \"block bootstrapped\" SE\n\n- One can also reduce panel to 2 periods: pre and post\n\n# Some Best Practices \n\n## Analyze Assumptions for Synthetic Control\n\n  - Key ID assumption cannot be \"tested\", as we never observe counterfactual\n  \n  - Conduct pre-treatment placebos for paralell paths / growths\n  \n    - Run the DiD on the last pre-treatment period\n  \n  - Graph pre-treatment trends\n  \n## Analyze Difference in Growths\n\n  - Mora and Reggio (2012) develop model that tests for parallel pre-treatment dynamics, and for the constancy of effects in the post-treatment period \n  \n## Analyze Difference in Growths\n  \n  - $L$ takes the difference between the current and some previous time period\n  \n  - $LX_t = X_{t-1}$ and $X_t = LX_{t+1}$\n  \nThen, we can use this operator to define changes in $Y$:\n  \n  - $\\Delta Y_t = (1 - L)Y_t = Y_t - Y_{t-1}$\n  \nYou can also get the second-difference operator (i.e. growth-in-growth, acceleration) by exponentializing the $L$ operator: \n  \n  - $\\Delta^2 X_t = (1-L)\\Delta X_t = (1 - L)(1 - L)X_t = (1 - L)^2 X_t$\n  \n## Analyze Difference in Growths\n\nMora and Reggio (2012) use $\\Delta_s = (1-L^s)$ \n\n- They define a \"parallel growth\" or \"parallel-$q$\" estimand, assuming\n\n$$E[\\Delta_s Y_{t^*+s}^0 | X, Z = 1] = E[\\Delta_s Y_{t^* + s}^0 | X, Z = 0],$$\n\n$$E[Y_{t^*+s}^0 | X, Z = 1] = \nE[Y_{t^*} | X, Z = 1] + \nE[\\Delta_s Y_{t^*+s}^0 | X, Z = 0]$$\n\n- Where $t^*$ denotes the last pre-treatment period\n\n*DiD* with parallel paths is a special case of the $s$-period operator, in \nwhich there is just 1 period: \n\n$$ \\alpha(1|X) = E[\\Delta Y_{t^* +1} | X, Z = 1] - E[\\Delta Y_{t^* +1} | X, Z = 0]$$\n\n## Analyze Difference in Growths\n\n  - They present a range of models for evaluating the assumptions upon which identification is based\n\n# What would Google do?\n\n## BSTS Models\n\n  - all we want to do with difference-in-differences is construct a synthetic counterfactual\n  \n  - our tools for prediction have grown well beyond the time-series models that economists enjoy\n  \n  - technological breakthroughs: \n    - in MCMC samplers: more flexible (realistic) models \n    - in machine learning algorithms: selection of more predictive specifications \n\n## BSTS Models\n\n\"We've been testing and applying structural time-series models for some time at Google. For example, we've used them to better understand the effectiveness of advertising campaigns and work out their return on investment. We've also applied the models to settings where a randomised experiment was available, to check how similar our effect estimates would have been without an experimental control.\n\n[...] Our main motivation behind creating the `CausalImpact` package has been to find a better way of measuring the impact of ad campaigns on outcomes. However, the `CausalImpact` package could be used for many other applications involving causal inference. Examples include problems found in economics, epidemiology, or the political and social sciences.\"\n\n## BSTS Models\n\nBasic idea behind `CausalImpact`: \n\n- \"We compute the posterior distribution of the counterfactual time series given the value of the target series in the pre-intervention period, along with the values of the controls in the post-intervention period. Subtracting the predicted from the observed response during the post-intervention period gives a semiparametric Bayesian posterior distribution for the causal effect.\"\n\n## BSTS Models\n\n`CausalImpact` and other such approaches take advantage of 3 sources of data:\n\n  1. the time-series behaviour of the response itself, prior to the intervention\n\n  2. the behaviour of other time series that were predictive of the target series prior to the intervention\n   \n  3. the available prior knowledge about the model parameters\n\n## BSTS Models\n\nAdvantages to `CausalImpact` and similar Bayesian state-space models...\n\n  - Do not assume i.i.d. errors \n  \n  - Do not consider treatment effects at one-period only\n  \n  - Do not impose relationships between synthetic control and predictors (uses automated methods to choose the most predictive)\n\n  - Propagates uncertainty over all parameters and variable selection\n  \n## BSTS Models\n\nSome key assumptions: \n\n  - the control time series were *themselves not affected by the intervention*\n  \n  - the relationship between covariates and treated time series, as established during the pre-period, remains stationary throughout the post-period\n \n## `CausalImpact`\n\nInstalling the package\n\n```{r, eval=FALSE}\ninstall.packages(\"devtools\")\nlibrary(devtools)\ndevtools::install_github(\"google/CausalImpact\")\n```\n```{r, eval=F}\nlibrary(CausalImpact)\n```\n\n\n## `CausalImpact`\n\nMake some fake data \n\n```{r, eval=T}\nset.seed(1)\nx1 <- 100 + arima.sim(model = list(ar = 0.999), n = 100)\ny <- 1.2 * x1 + rnorm(100)\ny[71:100] <- y[71:100] + 10\ntime.points <- seq.Date(as.Date(\"2014-01-01\"), \n                        by = 1, length.out = 100)\ndata <- zoo(cbind(y, x1), time.points)\n```\n\n## `CausalImpact`\n\n```{r, eval=T,echo=F}\nkable(head(data),digits = 2)\n```\n\n## `CausalImpact`\n\n```{r, echo=T, fig.width=5, fig.height=2.8,eval=T}\npar(cex = 0.85, oma = c(0, 0, 0, 0), mar = c(3, 2, 1, 1))\nmatplot(data, type = \"l\", lwd = 1.5)\n```\n\n## `CausalImpact`\n\n1. Specify when to train the model (*pre-intervention period*)\n2. Specify when to begin predicting counterfactual (*post-intervention period*)\n\n```{r, eval=T}\npre.period <- as.Date(c(\"2014-01-01\", \"2014-03-11\"))\npost.period <- as.Date(c(\"2014-03-12\", \"2014-04-10\"))\n```\n\n## \n\n```{r, eval=T}\n(impact <- CausalImpact(data, pre.period, post.period))\n```\n\n\n\n## \n\n  - **Average** is the average DiD (across time) during the post-intervention period \n  - **Cumulative** column sums up DiD at individual time points \n    - useful perspective if the response variable represents a flow quantity (such as queries, clicks, visits, installs, sales, or revenue) rather than a stock quantity (such as number of users or stock price)\n\n\n## \n\n```{r, eval=T,results=\"asis\"}\nsummary(impact,\"report\")\n```\n\n\n## \n\n```{r, echo=T,eval=T}\nplot(impact) + theme_bw(base_size = 11)\n```\n\n## \n\n1. First panel shows the data and a counterfactual prediction for the post-treatment period. \n\n2. Second panel shows the difference between observed data and counterfactual predictions. This is the *pointwise* causal effect, as estimated by the model. \n\n3. Third panel adds up the pointwise contributions from the second panel, resulting in a plot of the *cumulative* effect of the intervention.\n\n## Using a custom model\n\n- Various adjustments to in-built model in `CausalImpact`\n\n- Other Bayesian Structural Time-Series models can be built with `bsts` and sampled with `CausalImpact`\n\n```{r, eval=FALSE}\n# Define post-period\npost.period <- c(71, 100)\n# Grab response\npost.period.response <- y[post.period[1] : post.period[2]]\n# Set response in data to NA\ny[post.period[1] : post.period[2]] <- NA\n# Set up some time-series model in bsts\nss <- AddLocalLevel(list(), y)\nbsts.model <- bsts(y ~ x1, ss, niter = 1000, ping = 0)\n# Train model, sample, and compare with observed response\nimpact <- CausalImpact(bsts.model = bsts.model,\n                       post.period.response = post.period.response)\n```\n\n## Using a custom model\n\n```{r, eval=TRUE}\nplot(impact)\n```\n\n## The main model in `CausalImpact`\n\n![BSTSdag](BSTS_DAG_small.png)\n\n## An invitation to collaborate\n\n  - new computational techniques enable much better prediction than current DiD uses\n\n  - `CausalImpact` uses a Gibbs sampler, could Stan do better? \n    - Stan can't do \"spike-and-slab\" due to degenerative spike\n    - but maybe this isn't necessary?\n  \n  - Agenda:\n    - Build something good using BSTS + HMC or Gibbs\n    - Benchmark synthetic control against real experimental controls and \"traditional\" DiD\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1445610248832.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2269154674",
    "id" : "3E393D5A",
    "lastKnownWriteTime" : 1445622566,
    "path" : "~/Dropbox/07 Methods/03_DiD/bayesianDiD/01_DiD_Presentation/01_DiD Presentation.Rmd",
    "project_path" : "01_DiD_Presentation/01_DiD Presentation.Rmd",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_markdown"
}