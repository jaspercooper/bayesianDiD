{
    "contents" : "---\ntitle: \"Difference-in-Difference Estimation\"\nauthor: \"Jasper Cooper\"\noutput: ioslides_presentation\n---\n```{r,echo=F}\nset.seed(12345)\nlibrary(ggplot2)\n```\n\n\n## Plan \n\n  1. What it is and why people use it\n  \n  2. Causal identification \n  \n  3. Frequentist Approaches to Estimation \n  \n  4. Sources of Bias and Over-Confidence \n  \n  5. What would google do?\n    - Bayesian Structural Time-Series \n    - An invitation to collaborate\n\n\n# What it is and why people use it\n\n## What it is\n\n- A method for constructing counterfactuals\n\n```{r,echo=FALSE,cache=T,warning=F,message=F}\n\n\ndat <- data.frame(\n  post = rep(1:10,each = 2),\n  treatment = rep(c(0,1),10)\n)\n\ndat$Y1 <- NA\ndat$Y0 <- NA\ndat$Y0[dat$treatment == 0] <- 10:1 + runif(10)\ndat$Y0[dat$treatment == 1] <- dat$Y0[dat$treatment == 0]+5\n\ndat$Y1 <- dat$Y0 + 2\ndat$Y <- NA\ndat$Y[dat$treatment == 0] <- dat$Y0[dat$treatment == 0]\ndat$Y[dat$treatment == 1&dat$post<6] <- dat$Y0[dat$treatment == 1&dat$post<6]\ndat$Y[dat$treatment == 1&dat$post>5] <- dat$Y1[dat$treatment == 1&dat$post>5]\ndat$Y_pred <- NA\ndat$Y_pred[dat$treatment == 1&dat$post>5] <- dat$Y0[dat$treatment == 1&dat$post>5]\ndat$treatment <- as.factor(dat$treatment)\n```\n```{r,echo=FALSE,cache=T,warning=F,message=F,fig.height=3}\nplot_dat_1 <- subset(dat,treatment == 1)\nY_at_end <- with(plot_dat_1,Y[post==10])\nY_at_start <- with(plot_dat_1,Y[post==1])\nggplot(plot_dat_1) + geom_line(aes(x = post, y = Y,color = treatment)) +\n  # geom_point(aes(x = post, y = Y_pred)) +\n  theme_bw() +\n  scale_color_discrete(\"\",labels = c(\"Treated\")) +\n  scale_x_continuous(\"Time\",\n                     breaks = c(2.5,5.5,7.5), \n                     labels = c(\"Pre\",\"Intervention\",\"Post\")) +\n  geom_vline(xintercept = 5.5) +\n  geom_hline(aes(yintercept = c(Y[post==1],\n                            Y[post==10])),\n             linetype = 2,size = .5) +\n  scale_y_continuous(\"Y\",breaks = round(c(0,15,10,5,Y_at_end,Y_at_start\n                            ),1)) +\n#   geom_segment(aes(x = 8, y = Y_pred[post==8], \n#                    xend = 8, yend = Y[post==8]),\n#                linetype = 3) +\n  coord_cartesian(ylim = c(0,17))\n\n```\n\n- $\\tau = 2$\n- $\\hat{\\tau} = -7.1$\n\n## What it is\n\n- A method for constructing counterfactuals\n\n```{r,echo=FALSE,cache=T,warning=F,message=F,fig.height=3}\nplot_dat_2 <- dat\n# I did a weird thing here and inverted the treatment indicator to keep the \n# colors constant, sorry about that:\nplot_dat_2$treatment <- as.factor(2-as.numeric(plot_dat_2$treatment))\nY_prediction <- with(plot_dat_2,Y_pred[post==7&treatment == 0])\nY_observed <- with(plot_dat_2,Y[post==7&treatment == 0])\nggplot(plot_dat_2) + geom_line(aes(x = post, y = Y,color = treatment)) +\n  geom_point(aes(x = post, y = Y_pred)) +\n  theme_bw() +\n  scale_color_discrete(\"\",labels = c(\"Treated\",\"Untreated\")) +\n  scale_x_continuous(\"Time\",\n                     breaks = c(2.5,5.5,7.5), \n                     labels = c(\"Pre\",\"Intervention\",\"Post\")) +\n  geom_vline(xintercept = 5.5) +\n  geom_hline(yintercept = c(Y_observed,\n                            Y_prediction),\n             linetype = 2,size = .5) +\n  scale_y_continuous(\"Y\",breaks = c(0,15,10,5,round(Y_observed,1),\n                                       round(Y_prediction,1))) +\n  geom_segment(x = 7, y = Y_prediction, \n                   xend = 7, yend = Y_observed,\n               linetype = 3)+\n  coord_cartesian(ylim = c(0,17))\n```\n\n- $\\tau = 2$ \n- $\\hat{\\tau} = 2$\n\n## What it is\n\n- We estimate causal effects as the difference between what we observe and what we predict we would have observed in the absence of \"treatment\"\n\n- Does not require that unobserved heterogeneity in baseline is equal cross-sectionally\n\n- Does require that unobserved heterogeneity in \"trends\" is equal cross-sectionally\n\n- Requires that you have more than two units at more than two times, with \n\n## Why people use it\n\n- Often things we can't randomize, or that have already happened in a non-random way\n\n- Often good reasons to believe that things will evolve similarly in time\n\n- In such cases, can provide causal estimate that accounts for unobserved heterogeneity in general trends, cross-sectional differences and treatment assignment propensities\n\n- Everything hinges on the validity of the counterfactual predictions\n\n## Main disadvantages\n\n- Easy to have over-confident estimates (serial correlation)\n\n- Easy to have biased estimates (violation of identification assumptions)\n\n\n# Identification assumptions\n\n## Traditional concerns \n\n  - Exclusion restriction still applies \n    - Can't be anything about being assigned to the treatment that affects outcomes except for the treatment\n  \n  - SUTVA\n    - includes both inter-temporal and cross-unit spillovers \n    - Damian Clarke (2015) has a paper on how to do DiD in presence of spillovers\n\n## Parallel paths, parallel growths\n\n  - Ideal situation = trends common across units \n    - but DiD actually viable even in presence of unit-specific trends\n\n  - **if untreated**, those who **received treatment** would have an \n  outcome equivalent to their **outcome in the last pre-treatment period, plus whatever change took place** in the periods among those who did not receive treatment \n## Parallel paths, parallel growths\n  \nRequires ignorability in *trends* \n\n  - not ignorability in all unobserved heterogeneity\n  - assumption that *changes* remain constant in the absence of treatment \n\n## Parallel paths, parallel growths\n\nIn the simplest case of common trends and two time periods\n\n  - we don't assume $E[Y(0)|Z=1] = E[Y(0)|Z=0]$\n\nbut: \n  \n  - $E[Y(0,1) - Y(0,0)|Z=1] = E[Y(0,1) - Y(0,0)|Z=0]$\n  \nWhere $Y(z_i,t)$\n\n## Parallel paths, parallel growths\n\n  - It is possible to do DiD even when there are unit-specific trends\n  \n  - $L$ takes the difference between the current and some previous time period\n  \n  - $LX_t = X_{t-1}$ and $X_t = LX_{t+1}$\n  \nThen, we can use this operator to define changes in $Y$:\n  \n  - $\\Delta Y_t = (1 - L)Y_t = Y_t - Y_{t-1}$\n  \nYou can also get the second-difference operator (i.e. growth-in-growth, acceleration) by exponentializing the $L$ operator: \n  \n  - $\\Delta^2 X_t = (1-L)\\Delta X_t = (1 - L)(1 - L)X_t = (1 - L)^2 X_t$\n  \n## Parallel paths, parallel growths\n\nMora and Reggio (2012) use $\\Delta_s = (1-L^s)$ \n\n- They define a \"parallel growth\" or \"parallel-$q$\" estimand, assuming:\n\n$$E[\\Delta_s Y_{t^*+s}^0 | X, D = 1] = E[\\Delta_s Y_{t^* + s}^0 | X, D = 0]$$\n\n*and* \n\n$$E[Y_{t^*+s}^0 | X, D = 1] = \nE[Y_{t^*} | X, D = 1] + \nE[\\Delta_s Y_{t^*+s}^0 | X, D = 0]$$\n\n- Where $t^*$ denotes the last pre-treatment period\n\n##\n\n  \n- this is a good argument for including lots of time-level covariates\n\n- what do time-level FE do here? i.e. if we think that each period \n  has independent time effects? \n  \n     - there definitely might be scope for writing this up as a Bayesian model\n       with time-level effects \n\n\n*DiD* with parallel paths is a special case of the $s$-period operator, in \nwhich there is just 1 period: \n\n$$ \\alpha(1|X) = E[\\Delta Y_{t^* +1} | X, D = 1] - \nE[\\Delta Y_{t^* +1} | X, D = 0]$$\n\n  \n\n\n## Frequentist Approaches to Estimation \n\nMath here \n- mention some of the estimators\n\n## Sources of Bias and Over-Confidence\n\n- serial correlation \n\n- violation of assumptions\n\n\n## What would Google do?\n\n- all we want to do with difference-in-differences is predict a counterfactual\n\n- our tools for prediction have grown well beyond the time-series models that economists like\n\n- we can use a machine-learning logic in the pre-treatment (training) data to predict the counterfactual in the post-treatment period (testing)\n\n## What would Google do?\n\nWe've been testing and applying structural time-series models for some time at Google. For example, we've used them to better understand the effectiveness of advertising campaigns and work out their return on investment. We've also applied the models to settings where a randomised experiment was available, to check how similar our effect estimates would have been without an experimental control.\n\nOur main motivation behind creating the `CausalImpact` package has been to find a better way of measuring the impact of ad campaigns on outcomes. However, the `CausalImpact` package could be used for many other applications involving causal inference. Examples include problems found in economics, epidemiology, or the political and social sciences.\n\n## What would Google do?\n\n- construct a synthetic control using the posterior predictive distribution\n\n- ...of a very flexible \n\n## Bayesian State-Space Model\n\n![BSSM](BSTS_DAG_small.png)\n\n## An R package for causal inference using Bayesian structural time-series models\n\n#### What does the package do?\nThis R package implements an approach to estimating the causal effect of a designed intervention on a time series. For example, how many additional daily clicks were generated by an advertising campaign? Answering a question like this can be difficult when a randomized experiment is not available.\n\n#### How does it work?\nGiven a response time series (e.g., clicks) and a set of control time series (e.g., clicks in non-affected markets or clicks on other sites), the package constructs a Bayesian structural time-series model. This model is then used to try and predict the counterfactual, i.e., how the response metric would have evolved after the intervention if the intervention had never occurred. For details, see: [Brodersen et al., Annals of Applied Statistics (2015)](http://research.google.com/pubs/pub41854.html).\n\n#### What assumptions does the model make?\nAs with all non-experimental approaches to causal inference, valid conclusions require strong assumptions. In the case of CausalImpact, we assume that there is a set control time series that were *themselves not affected by the intervention.* If they were, we might falsely under- or overestimate the true effect. Or we might falsely conclude that there was an effect even though in reality there wasn't. The model also assumes that the relationship between covariates and treated time series, as established during the pre-period, remains stable throughout the post-period (see `model.args$dynamic.regression` for a way of relaxing this assumption). Finally, it's important to be aware of the *priors* that are part of the model (see `model.args$prior.level.sd` in particular).\n\n#### How is the package structured?\nThe package is designed to make counterfactual inference as easy as fitting a regression model, but much more powerful, provided the assumptions above are met. The package has a single entry point, the function `CausalImpact()`. Given a response time series and a set of control time series, the function constructs a time-series model, performs posterior inference on the counterfactual, and returns a `CausalImpact` object. The results can be summarized in terms of a table, a verbal description, or a plot.\n\n\n## 1. Installing the package\n\nTo install `CausalImpact`, type the following commands into an R session:\n\n```{r, eval=FALSE}\ninstall.packages(\"devtools\")\nlibrary(devtools)\ndevtools::install_github(\"google/CausalImpact\")\n```\n\nOnce installed, the package can be loaded in a given R session using:\n\n```{r, message=FALSE, warning=FALSE, eval=FALSE}\nlibrary(CausalImpact)\n```\n\n## 2. Creating an example dataset\n\nTo illustrate how the package works, we create a simple toy dataset. It consists of a response variable `y` and a predictor `x1`. Note that in practice, we'd strive for including many more predictor variables and let the model choose an appropriate subset. The example data has 100 observations. We create an *intervention effect* by lifting the response variable by 10 units after timepoint 71.\n```{r, eval=FALSE}\nset.seed(1)\nx1 <- 100 + arima.sim(model = list(ar = 0.999), n = 100)\ny <- 1.2 * x1 + rnorm(100)\ny[71:100] <- y[71:100] + 10\ndata <- cbind(y, x1)\n```\n\nWe now have a simple matrix with 100 rows and two columns:\n```{r, eval=FALSE}\ndim(data)\nhead(data)\n```\n\nWe can visualize the generated data using:\n```{r, eval=FALSE, eval=FALSE}\nmatplot(data, type = \"l\")\n```\n```{r, echo=FALSE, fig.width=5, fig.height=2.8,eval=F}\npar(cex = 0.85, oma = c(0, 0, 0, 0), mar = c(3, 2, 1, 1))\nmatplot(data, type = \"l\", lwd = 1.5)\n```\n\n## 3. Running an analysis\n\nTo estimate a causal effect, we begin by specifying which period in the data should be used for training the model (*pre-intervention period*) and which period for computing a counterfactual prediction (*post-intervention period*).\n```{r, eval=FALSE}\npre.period <- c(1, 70)\npost.period <- c(71, 100)\n```\n\nThis says that time points 1 ... 70 will be used for training, and time points 71 ... 100 will be used for computing predictions. Alternatively, we could specify the periods in terms of dates or time points; see [Section 5](#working-with-dates-and-times) for an example.\n\nTo perform inference, we run the analysis using:\n```{r, eval=FALSE}\nimpact <- CausalImpact(data, pre.period, post.period)\n```\n\nThis instructs the package to assemble a structural time-series model, perform posterior inference, and compute estimates of the causal effect. The return value is a `CausalImpact` object.\n\n## 4. Plotting the results\n\nThe easiest way of visualizing the results is to use the `plot()` function that is part of the package:\n```{r, fig.width=8, fig.height=6, eval=FALSE}\nplot(impact)\n```\n```{r, include=FALSE}\nlibrary(ggplot2)\n```\n```{r, echo=FALSE,eval=F}\nplot(impact) + theme_bw(base_size = 11)\n```\n\nBy default, the plot contains three panels. The first panel shows the data and a counterfactual prediction for the post-treatment period. The second panel shows the difference between observed data and counterfactual predictions. This is the *pointwise* causal effect, as estimated by the model. The third panel adds up the pointwise contributions from the second panel, resulting in a plot of the *cumulative* effect of the intervention.\n\nRemember, once again, that all of the above inferences depend critically on the assumption that the covariates were not themselves affected by the intervention. The model also assumes that the relationship between covariates and treated time series, as established during the pre-period, remains stable throughout the post-period.\n\n## 5. Working with dates and times\n\nIt is often more natural to feed a time-series object into `CausalImpact()` rather than a data frame. For example, we might create a `data` variable as follows:\n\n```{r, eval=FALSE}\ntime.points <- seq.Date(as.Date(\"2014-01-01\"), by = 1, length.out = 100)\ndata <- zoo(cbind(y, x1), time.points)\nhead(data)\n```\n\nWe can now specify the pre-period and the post-period in terms of time points rather than indices:\n\n```{r, eval=FALSE}\npre.period <- as.Date(c(\"2014-01-01\", \"2014-03-11\"))\npost.period <- as.Date(c(\"2014-03-12\", \"2014-04-10\"))\n```\n\nAs a result, the x-axis of the plot shows time points instead of indices:\n\n```{r, fig.width=8, fig.height=6, eval=FALSE}\nimpact <- CausalImpact(data, pre.period, post.period)\nplot(impact)\n```\n```{r, echo=FALSE, eval=FALSE}\nimpact <- CausalImpact(data, pre.period, post.period)\nplot(impact) + theme_bw(base_size = 11)\n```\n\n## 6. Printing a summary table\n\nTo obtain a numerical summary of the analysis, we use:\n```{r, eval=FALSE}\nsummary(impact)\n```\n\nThe **Average** column talks about the average (across time) during the post-intervention period (in the example: time points 71 through 100). The **Cumulative** column sums up individual time points, which is a useful perspective if the response variable represents a flow quantity (such as queries, clicks, visits, installs, sales, or revenue) rather than a stock quantity (such as number of users or stock price).\n\nIn the example, the estimated average causal effect of treatment was 11 (rounded to a whole number; for full precision see `impact$summary`). This is because we observed an average value of 99 but would have expected an average value of only 89. The 95% posterior interval of the average effect is [9.8, 11]. Since this excludes 0, we (correctly) conclude that the intervention had a causal effect on the response variable. Since we generated the data ourselves, we know that we injected a true effect of 10, and so the model accurately recovered ground truth. One reason for this is that we ensured, by design, that the covariate `x1` was not itself affected by the intervention. In practice, we must always reason whether this assumption is justified.\n\nFor additional guidance about the correct interpretation of the summary table, the package provides a verbal interpretation, which we can print using:\n```{r, eval=FALSE}\nsummary(impact, \"report\")\n```\n\nThe individual numbers in the table, at full precision, can be accessed using:\n```{r, eval=FALSE}\nimpact$summary\n```\n\nSee below for tips on how to use these commands with *knitr* / *R Markdown*.\n\n## 7. Adjusting the model\n\nSo far, we've simply let the package decide how to construct a time-series model for the available data. However, there are several options that allow us to gain a little more control over this process. These options are passed into `model.args` as individual list elements, for example:\n```{r, eval=FALSE}\nimpact <- CausalImpact(..., model.args = list(niter = 5000, nseasons = 7))\n```\n\n### Available options\n\n* `niter` Number of MCMC samples to draw. More samples lead to more accurate inferences. Defaults to __1000__.\n\n* `standardize.data` Whether to standardize all columns of the data before fitting the model. This is equivalent to an empirical Bayes approach to setting the priors. It ensures that results are invariant to linear transformations of the data. Defaults to __TRUE__.\n\n* `prior.level.sd` Prior standard deviation of the Gaussian random walk of the local level. Expressed in terms of data standard deviations. Defaults to __0.01__, a typical choice for  well-behaved and stable datasets with low residual volatility after regressing out known predictors (e.g., web searches or sales in high quantities). When in doubt, a safer option is to use __0.1__, as validated on synthetic data, although this may sometimes give rise to unrealistically wide prediction intervals.\n\n* `nseasons` Period of the seasonal components. In order to include a seasonal component, set this to a whole number greater than 1. For example, if the data represent daily observations, use 7 for a day-of-week component. This interface currently only supports up to one seasonal component. To specify multiple seasonal components, use bsts to specify the model directly, then pass the fitted model in as bsts.model. Defaults to __1__, which means no seasonal component is used.\n\n* `season.duration` Duration of each season, i.e., number of data points each season spans. Defaults to __1__. For example, to add a day-of-week component to data with daily granularity, use __model.args = list(nseasons = 7, season.duration = 1)__. To add a day-of-week component to data with hourly granularity, set __model.args = list(nseasons = 7, season.duration = 24)__.\n\n* `dynamic.regression` Whether to include time-varying regression coefficients. In combination with a time-varying local trend or even a time-varying local level, this often leads to overspecification, in which case a static regression is safer. Defaults to __FALSE__.\n\n## 8. Using a custom model\n\nInstead of using the default model constructed by the CausalImpact package, we can use the bsts package to specify our own model. This provides the greatest degree of flexibility.\n\nBefore constructing a custom model, we set the observed data in the post-treatment period to NA, reflecting the fact that the counterfactual response is unobserved after the intervention. We keep a copy of the actual observed response in the variable `post.period.response`.\n```{r, eval=FALSE}\npost.period <- c(71, 100)\npost.period.response <- y[post.period[1] : post.period[2]]\ny[post.period[1] : post.period[2]] <- NA\n```\n\nWe next set up and estimate a time-series model using the bsts package. Here is a simple example:\n```{r, echo=FALSE, eval=FALSE}\nss <- AddLocalLevel(list(), y)\nbsts.model <- bsts(y ~ x1, ss, niter = 1000, ping = 0)\n```\n```{r, eval=FALSE}\nss <- AddLocalLevel(list(), y)\nbsts.model <- bsts(y ~ x1, ss, niter = 1000)\n```\n\nFinally, we call `CausalImpact()`. Instead of providing input data, we simply pass in the fitted model object (`bsts.model`). We also need to provide the actual observed response. This is needed so that the package can compute the difference between predicted response (stored in `bsts.model`) and actual observed response (stored in `post.period.response`).\n```{r, eval=FALSE}\nimpact <- CausalImpact(bsts.model = bsts.model,\n                       post.period.response = post.period.response)\n```\n\nThe results can be inspected in the usual way:\n```{r, eval=FALSE}\nplot(impact)\nsummary(impact)\nsummary(impact, \"report\")\n```\n\n\n\n## An invitation to collaborate\n\n  - new computational techniques enable much better prediction than current DiD uses\n\n  - `CausalImpact` uses a Gibbs sampler, could Stan do better? \n    - Stan can't do \"spike-and-slab\" due to degenerative spike\n    - but maybe this isn't necessary?\n  \n  - Agenda:\n    - Build something good using BSTS + HMC or Gibbs\n    - Benchmark synthetic control against real experimental controls and \"traditional\" DiD\n    \n  - \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1445610248832.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2372058984",
    "id" : "3E393D5A",
    "lastKnownWriteTime" : 1445609398,
    "path" : "~/Dropbox/07 Methods/03_DiD/bayesianDiD/01_DiD_Presentation/01_DiD Presentation.Rmd",
    "project_path" : "01_DiD_Presentation/01_DiD Presentation.Rmd",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_markdown"
}